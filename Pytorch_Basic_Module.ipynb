{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCuWlb+PJgqiz4xmmwIdNM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdul-AI-creator/Abdul-AI-creator/blob/main/Pytorch_Basic_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a7TdjSzUFBvx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic autograd example 1"
      ],
      "metadata": {
        "id": "SAb7-D2nFwjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tensor\n",
        "x = torch.tensor(1. ,requires_grad=True)\n",
        "w = torch.tensor(2. ,requires_grad=True)\n",
        "b = torch.tensor(3. ,requires_grad=True)"
      ],
      "metadata": {
        "id": "9R2QqBGkFtum"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computational Graph\n",
        "y = w * x + b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU1gLoVlFtqt",
        "outputId": "85ad6c76-ccce-495e-c62b-9534b1266567"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "uPop-nLlFtne"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print Gradients\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZhnxDRuFthP",
        "outputId": "ad85c89a-75c1-4882-f6c6-e045e7862b9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic autograd example 2**"
      ],
      "metadata": {
        "id": "XldNCqsxG6fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(10, 3)\n",
        "y =torch.randn(10, 2)"
      ],
      "metadata": {
        "id": "Wju5iDKNFtdp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6MEDDSlFtaE",
        "outputId": "0d14138b-0488-4112-8d53-845e7435c209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1264, 0.9934, 0.7934],\n",
              "        [0.9520, 0.1711, 0.4189],\n",
              "        [0.0529, 0.3872, 0.8397],\n",
              "        [0.4842, 0.2677, 0.4434],\n",
              "        [0.3410, 0.8585, 0.6895],\n",
              "        [0.8638, 0.7206, 0.9231],\n",
              "        [0.5750, 0.3488, 0.3496],\n",
              "        [0.7300, 0.4347, 0.5083],\n",
              "        [0.9405, 0.0491, 0.3077],\n",
              "        [0.4858, 0.0297, 0.4563]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9EApXg-FtWn",
        "outputId": "b71f7142-67bd-4ee4-fe5d-3b4660c6a966"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6259,  0.5312],\n",
              "        [ 0.1523,  1.5146],\n",
              "        [-0.9905, -0.1823],\n",
              "        [-0.5362,  2.0518],\n",
              "        [ 0.0953, -0.1191],\n",
              "        [-2.1011, -1.7400],\n",
              "        [-0.5224, -0.8912],\n",
              "        [-3.7888, -0.5088],\n",
              "        [-0.3574, -0.7572],\n",
              "        [-0.9674, -0.3828]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**build fully Connected Layer**"
      ],
      "metadata": {
        "id": "CdqXgO88HPID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(3 ,2)\n",
        "print('w: ',linear.weight)\n",
        "print('b: ',linear.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pyj-si1FtS0",
        "outputId": "da95c89f-af2c-4624-b9c3-8407eb086838"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[-0.2798,  0.5682,  0.4313],\n",
            "        [ 0.4809, -0.5478, -0.5766]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([-0.2170, -0.5056], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion =nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters() ,lr=0.001)"
      ],
      "metadata": {
        "id": "f3ezu7z7FtPu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "pred = linear(x)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6nGSEdaIMlF",
        "outputId": "a4728886-4cbf-424c-d645-40178ab17fca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6543, -1.4465],\n",
              "        [-0.2055, -0.3831],\n",
              "        [ 0.3504, -1.1765],\n",
              "        [-0.0091, -0.6751],\n",
              "        [ 0.4728, -1.2095],\n",
              "        [ 0.3489, -1.0172],\n",
              "        [-0.0289, -0.6217],\n",
              "        [ 0.0450, -0.6858],\n",
              "        [-0.3195, -0.2576],\n",
              "        [-0.1392, -0.5514]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute loss\n",
        "loss =criterion(pred ,y)\n",
        "print('loss: ',loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrRbdXLWIMeU",
        "outputId": "514e0df9-df27-4e78-933d-feec6617dcd6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.1823105812072754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Pass\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "GbyEqCd2IMbk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('dL/dw' ,linear.weight.grad)\n",
        "print('dL/db' ,linear.bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSmoIFWuIMYm",
        "outputId": "5e27b7cd-de7f-4a4d-befa-ebedd39bca42"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dL/dw tensor([[ 0.5913,  0.5826,  0.7258],\n",
            "        [-0.2763, -0.3783, -0.4412]])\n",
            "dL/db tensor([ 1.0811, -0.7540])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step Gradient\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "hp6VzG-SIMV6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also perform gradient descent at the low level.\n",
        "linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "linear.bias.data.sub_(0.01 * linear.bias.grad.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yDtrUkvJllj",
        "outputId": "f22f7ab6-96fd-49e2-843b-1e0ac6873d0d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2289, -0.4973])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the loss after 1-step gradient descent.\n",
        "pred= linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('Loss after one Step Optimization',loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxMWGq5AIL4Z",
        "outputId": "88fce96e-c119-4a4c-90de-65be3338f52e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after one Step Optimization 2.145641803741455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data from numpy"
      ],
      "metadata": {
        "id": "TrnTpomAKFTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([[1,2] ,[3,4]])\n",
        "y=torch.from_numpy(x)\n",
        "z = y.numpy()"
      ],
      "metadata": {
        "id": "Zv1W_3syJCRC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input PipeLine**"
      ],
      "metadata": {
        "id": "C7wIAYlsKsh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Download and convert Cifar-10 Dataset`"
      ],
      "metadata": {
        "id": "kAw18-rgK1Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torchvision.datasets.CIFAR10(root = '../../data/',train =True ,transform=transforms.ToTensor(),download=True)\n",
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4j6z2ePJCTr",
        "outputId": "33cdf8b1-8933-48ec-bc2c-35da538c7008"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 39.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ../../data/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch one data pair (Read data from disk)\n",
        "images ,labels =train_ds[0]\n",
        "print(images.size())\n",
        "print(labels)\n",
        "images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ije9QL6_JCWZ",
        "outputId": "6f9c305f-4ab6-4663-c459-839391a1627a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
              "         [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
              "         [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
              "         ...,\n",
              "         [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
              "         [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
              "         [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
              "\n",
              "        [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
              "         [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
              "         [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
              "         ...,\n",
              "         [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
              "         [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
              "         [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
              "\n",
              "        [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
              "         [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
              "         [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
              "         ...,\n",
              "         [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
              "         [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
              "         [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Data Loader** `provides queues and threads in a very simple way)`"
      ],
      "metadata": {
        "id": "w_A_tp0-MNX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl =torch.utils.data.DataLoader(dataset =train_ds ,batch_size = 64 ,shuffle=True)\n",
        "train_dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0KwEleZJCci",
        "outputId": "119756b5-528e-4910-8fd4-cda3dc5879f3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fa1a848cbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When iteration starts Que and thread starts to load data from  Files"
      ],
      "metadata": {
        "id": "qeFQcttlM9uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_dl)\n",
        "# mini batch images and labels\n",
        "images, labels = next(data_iter)"
      ],
      "metadata": {
        "id": "Qvpsv1YPJCgC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USAGE OF DATALOADERA**"
      ],
      "metadata": {
        "id": "B-gtGmG-b07T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images ,labels in train_dl:\n",
        "  pass"
      ],
      "metadata": {
        "id": "nYH2xcCkJCi0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input pipeline for custom dataset**"
      ],
      "metadata": {
        "id": "MLrz570tcKbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomerDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,data,labels):\n",
        "    self.data =data\n",
        "    self.labels =labels\n",
        "    # Todo\n",
        "    # initialize filepath or list of file name\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    # change 0 to total size of dataset\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self ,index):\n",
        "\n",
        "    # todo\n",
        "    # Read one data from file (e.g. use numpy.fromfile , PIL.Image.open)\n",
        "    # Preproces data (e.g torchvision.Transform)\n",
        "    # return Data pair(images and labels)\n",
        "    return self.data[index] ,self.labels[index]\n"
      ],
      "metadata": {
        "id": "nG0YmE-4b8bu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(100,10)\n",
        "labels = torch.randint(0,2, (100,))\n",
        "custom_ds =CustomerDataset(data , labels)"
      ],
      "metadata": {
        "id": "DtlXOYDDiFpQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(custom_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQChe2KZiFfo",
        "outputId": "5e779ac3-acbc-4a75-d02e-abf20ad7ccbc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use the prebuilt data loader"
      ],
      "metadata": {
        "id": "VqSYyiJrfXHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dl =torch.utils.data.DataLoader(dataset=custom_ds ,batch_size = 64 ,shuffle=True)\n",
        "train_dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kykyc-Nob7K8",
        "outputId": "f0ebe249-d22a-4cd5-d615-0e8411a8ceae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fa1a8698cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and load the pretrained ResNet-18."
      ],
      "metadata": {
        "id": "dqH0q9keinIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet =torchvision.models.resnet18(pretrained=True)\n",
        "resnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx6fDsusb7IT",
        "outputId": "d1aa6089-0b19-46e2-8b9d-c74befd2e610"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 162MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to finetune only the top layer of the model"
      ],
      "metadata": {
        "id": "ygPMoa87k96_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in resnet.parameters():\n",
        "  param.requires_grad=False\n",
        "  # Replace the top layer for finetuning.\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features ,100)\n",
        "\n",
        "images =torch.randn(64,3,224,224)\n",
        "output = resnet(images)\n",
        "print(output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZALWdp9b7FQ",
        "outputId": "13f3ae19-7b60-4c4b-ce69-d6bbea7ff093"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SZw-hGoSqXC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet.state_dict(),'model_resnet.csv')"
      ],
      "metadata": {
        "id": "U7cqVld7b68f"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GbTaGb3JClS",
        "outputId": "403ef516-a1df-4c2c-9375-425e2df863fb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-c2ed98f4147d>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet.load_state_dict(torch.load('params.ckpt'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tp6H_A62JCoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ewgoc1kvJCqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}