{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnuBICUm8GwSTO+T4cSYEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdul-AI-creator/Abdul-AI-creator/blob/main/Pytorch_intermediate(bidirectional_recurrent_neural_network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important Libraries"
      ],
      "metadata": {
        "id": "qhGvb4u8AvTq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dxtH0un__hhe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device Comfiguration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5av-aS7DA06N",
        "outputId": "7181b6f4-8c84-4b92-b0f6-6730aa603cb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "CexEexA2CH8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 28\n",
        "n_classes = 10\n",
        "input_size =28\n",
        "hidden_size=128\n",
        "n_layers = 2\n",
        "n_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.003"
      ],
      "metadata": {
        "id": "6rzZbK6QA00N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "LBe01KifCuM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torchvision.datasets.MNIST(root = './data', train=True , transform = transforms.ToTensor() ,download=True)\n",
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDDc7KdRA0zL",
        "outputId": "f569e964-f211-4f12-dcbc-37b4decc267c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 42.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 43.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.95MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = torchvision.datasets.MNIST(root ='./data' ,train=False , transform = transforms.ToTensor())\n",
        "test_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjWrC_SnA0sK",
        "outputId": "e7672de5-c970-422d-9ec4-62baa421f829"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoaders"
      ],
      "metadata": {
        "id": "0x26EFfXD93k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset =train_ds ,batch_size=batch_size ,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset =test_ds , batch_size = batch_size ,shuffle =False )"
      ],
      "metadata": {
        "id": "OHpOh09kA0rP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bidirectional Recurrent Neural Network(many to one)"
      ],
      "metadata": {
        "id": "_N1sZxRKEqWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "  def __init__(self ,input_size ,hidden_size ,n_layers ,n_classes):\n",
        "    super(BiRNN ,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.lstm = nn.LSTM(input_size ,hidden_size ,n_layers ,batch_first=True ,bidirectional=True) #  long short-term memory (LSTM)\n",
        "    self.fc = nn.Linear(hidden_size*2 , n_classes)    # 2 for Bidirectional\n",
        "\n",
        "  def forward(self ,x):\n",
        "          # set initial state\n",
        "    h0 = torch.zeros(self.n_layers*2 ,x.size(0) ,self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.n_layers*2 ,x.size(0) ,self.hidden_size).to(device)\n",
        "    # Forward Propagate LSTM\n",
        "    out, _ =self.lstm(x, (h0 ,c0))      # out:  tensor of shape (batch_size ,seq_length ,hidden_size*2)\n",
        "    # decode the hidden state of the last time step\n",
        "    out = self.fc(out[: , -1 , :])\n",
        "    return out\n",
        "\n",
        "model =BiRNN(input_size ,hidden_size ,n_layers , n_classes).to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "Y6-GfvikA0mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b687a5c-766e-406b-ff38-8814b91af8d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiRNN(\n",
              "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss and Optimizer**"
      ],
      "metadata": {
        "id": "JpIf1vrfVI28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters() ,lr = learning_rate)"
      ],
      "metadata": {
        "id": "oxGWt4IyA0lG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "yphPJdMbWNOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step =len(train_loader)\n",
        "for epoch in range(n_epochs):\n",
        "  for i ,(images ,labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1 ,seq_length ,input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs ,labels)\n",
        "\n",
        "    # backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 ==0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}] ,Loss: {:.4f}'.format(epoch+1 ,n_epochs ,i +1, total_step ,loss.item()))"
      ],
      "metadata": {
        "id": "sHYk5XVnA0gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270823dc-517a-4c2a-a52f-fc7d8572cb23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600] ,Loss: 0.6722\n",
            "Epoch [1/2], Step [200/600] ,Loss: 0.4898\n",
            "Epoch [1/2], Step [300/600] ,Loss: 0.2111\n",
            "Epoch [1/2], Step [400/600] ,Loss: 0.2260\n",
            "Epoch [1/2], Step [500/600] ,Loss: 0.2155\n",
            "Epoch [1/2], Step [600/600] ,Loss: 0.0977\n",
            "Epoch [2/2], Step [100/600] ,Loss: 0.1057\n",
            "Epoch [2/2], Step [200/600] ,Loss: 0.0445\n",
            "Epoch [2/2], Step [300/600] ,Loss: 0.0940\n",
            "Epoch [2/2], Step [400/600] ,Loss: 0.1294\n",
            "Epoch [2/2], Step [500/600] ,Loss: 0.1141\n",
            "Epoch [2/2], Step [600/600] ,Loss: 0.0334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the Model**"
      ],
      "metadata": {
        "id": "yghcDCA9b2aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct =0\n",
        "  total = 0\n",
        "  for images , labels in test_loader:\n",
        "    images = images.reshape(-1 , seq_length ,input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs =model(images)\n",
        "    _, predicted =torch.max(outputs.data ,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print('Test Accuracy on model of 10000 test images: {} %'.format(100 * correct/total))\n",
        "torch.save(model.state_dict() ,'BiRNN_model.csv')"
      ],
      "metadata": {
        "id": "MNjtxsR_A0fI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d048a85-2445-487b-8f2c-5ad09313fbb1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy on model of 10000 test images: 97.71 %\n"
          ]
        }
      ]
    }
  ]
}